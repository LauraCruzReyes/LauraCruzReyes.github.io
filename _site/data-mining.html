<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <link rel="stylesheet" href="/style.css"/>
  <link rel="icon" type="image/ico" href="favicon.ico">
  
  <title></title>
</head>

<body>
  <header>
    <nav>
  <ul>
    <li>
      <a href="/index.html">Home</a>
      <div class="dropdown">
        <a href="http://www.itcm.edu.mx/index.php">ITCM</a>
        <a href="http://www.itcm.edu.mx/mcc/">Master Program</a>
        <a href="http://www.itcm.edu.mx/index.php/2012-03-12-21-20-38/2012-04-17-19-42-12/doctorado-en-ciencias-en-computacion">Doctoral Program</a>
      </div>
    </li>
    <li>
      <a href="#">Research</a>
      <div class="dropdown">
        <a href="thesis.html">Theses</a>
        <a href="publications.html">Publications</a>
        <a href="funded-research.html">Funded Research</a>
        <a href="My-research-group.html">My research group</a>
      </div>
    </li>
    <li>
      <a href="#">Teaching</a>
      <div class="dropdown">
        <a href="data-mining.html">Data Mining</a>
        <a href="probability-statistics.html">Probability and Statistics</a>
      </div>
    </li>
    <li>
      <a href="#">Editorial</a>
      <div class="dropdown">
        <a href="http://smia.mx/komputersapiens/">Komputer Sapiens</a>
      </div>
    </li>
    <li>
      <a href="#">Resources</a>
      <div class="dropdown">
        <a href="http://www.lanti.org.mx/">Open HPC Lab</a>
      </div>
    </li>
    <li><a href="vitae.pdf" class="button">Vitae</a></li>
    <li><a href="internal.html" class="button">Internal</a></li>
  </ul>
</nav>

  </header>
  <main>
    <h2 id="data-mining">Data Mining</h2>

<h3 id="syllabus">Syllabus</h3>

<ol>
  <li>Introduction to machine learning<br />
Week 1———–<a href="https://www.dropbox.com/sh/8il7mgw018cd9g4/AAAO_nC7j8119gWKVz9hZ-dma?dl=0" title="1.1">1.1</a> Data mining, big data analytics and data science.<br />
Week 1———–<a href="https://www.dropbox.com/sh/6ru3aptihdchalk/AABPhlhZNf0ZGcjc6UcsTG0ma?dl=0" title="1.2">1.2</a> Machine Learning.<br />
Week 1———–<a href="https://www.dropbox.com/sh/367mnk7sv3u7vvs/AABMt_rteRP9Wk0V2AxwCtZJa?dl=0" title="1.3">1.3</a> Learning: supervised, unsupervised, by reinforcement</li>
  <li>Supervised learning<br />
Week 2———–<a href="https://www.dropbox.com/sh/tfemmgphr94e6j4/AAC6HQ8_8lU4kvQGlShKUkuEa?dl=0" title="2.1">2.1</a> Nearest neighbors.<br />
Weeks 3-4——-<a href="https://www.dropbox.com/sh/72gvhg1lhb217e5/AADJ4fpCkTBYGSPDla7gk36pa?dl=0" title="2.2">2.2</a> Decision tree.<br />
Weeks 5-6——-<a href="https://www.dropbox.com/sh/k3yfk84u5q5jsqf/AADUHo176HkMmb097vJhN6l3a?dl=0" title="2.3">2.3</a> Bayesian classification.<br />
Week 7———–<a href="https://www.dropbox.com/sh/vxlb2iye8qbf4c3/AADnhIPbPHZ4WquKH6UqzAxda?dl=0" title="2.4">2.4</a> Rule-Based classification. Rought sets.<br />
Week 7———–<a href="https://www.dropbox.com/sh/smgmldezxqbof54/AACc8tAlNjAZpS-XI5kaa3rHa?dl=0" title="2.5">2.5</a> Other classification techniques. SVM.</li>
  <li>Unsupervised learning<br />
Weeks 8-9——-<a href="https://www.dropbox.com/sh/uoqfifll26lf1zq/AAB6WLZ1-Um0tkfqSan3kYn3a?dl=0" title="3.1">3.1</a> Partitional clustering. Kmeans algorithm.<br />
Week 10———<a href="https://www.dropbox.com/sh/y2vf0mysnl4khj4/AAD57ltaezlqp4F9Q2sMIh-6a?dl=0" title="3.2">3.2</a> Hierarchical clustering. Agglomerative algorithms.</li>
  <li>Association techniques<br />
Weeks 11-12—<a href="https://www.dropbox.com/sh/wftczlf10lrgyq6/AACXq_j9AozMueceQgzTP2XVa?dl=0" title="4.1">4.1</a> Apriori algorithm.<br />
Week 13———<a href="https://www.dropbox.com/sh/so75eqvncakg7hv/AAAQdS5vDOsmdc0EjOJcgxEwa?dl=0" title="4.2">4.2</a> Association rules generation algorithms.</li>
  <li>Reinforcement learning<br />
Week 14———<a href="https://www.dropbox.com/sh/ny9fpr6dctr56jg/AACGwlFkg6odtlkzKVFKdBJ7a?dl=0" title="5.1">5.1</a> Markov chain.<br />
Week 14———<a href="https://www.dropbox.com/sh/308fof4leugtpco/AAARtuaDDlaQk21nQAmqlFxIa?dl=0" title="5.2">5.2</a> Theoretical foundation of SARSA algorithm.<br />
Weeks 15-16—<a href="https://www.dropbox.com/sh/2hnp53v3i8kz3qy/AACs1Xbc-t2FjopgH1OhT02ga?dl=0" title="5.3">5.3</a> SARSA algorithm.</li>
</ol>

<h3 id="course-grading-policy-the-components-of-the-course-grade-for-each-evaluation-are">Course Grading Policy The components of the course grade for each evaluation are:</h3>

<ul>
  <li>60% Written exams (E1, E2, E3, E4, E5, E6, E7),</li>
  <li>40% Laboratory exercises (L1, L2, L3, L4, L5, L6, L7).</li>
  <li>The passing grade for this course is 70 (evaluations average).</li>
</ul>

<h3 id="course-administration">Course Administration</h3>

<ol>
  <li>
    <p><a href="https://www.dropbox.com/sh/y772otye2i01pej/AADFwJjIU34jI-575RIX1NT9a?dl=0" title="Progress">Progress</a>: it contains official syllabus, grades and attendance.</p>
  </li>
  <li>
    <p>Notes downloading: go to each topic of the English syllabus.</p>
  </li>
  <li>
    <p>Labs downloading: <a href="https://www.dropbox.com/sh/0mnbh4cnujmwukc/AAC9-I_GVzcpx5iBy7qYGmPja?dl=0" title="Lab1">Lab1</a>, <a href="https://www.dropbox.com/sh/mse4e7b5yzqxxmq/AABdee631OrY8nOF_uSZWiwpa?dl=0" title="Lab2">Lab2</a>, <a href="https://www.dropbox.com/sh/p0lkvtc8wb3e6cn/AACU0YVzZOjJ1NDk1p_c-eawa?dl=0" title="Lab3">Lab3</a>, <a href="https://www.dropbox.com/sh/bnz10v9cl3x8re9/AADM9jMbaksQWjV2H9xL1Bcra?dl=0" title="Lab4">Lab4</a>, <a href="https://www.dropbox.com/sh/zcz1dij4cxs9qw2/AABYbQA_0-gXJGu2Ycc6DRPua?dl=0" title="Lab5">Lab5</a>, <a href="https://www.dropbox.com/sh/1x3bi3rcup4okff/AADNBMbr4wZMHypE-JX1ruh-a?dl=0" title="Lab6">Lab6</a>, <a href="https://www.dropbox.com/sh/2cp842ikybbagky/AADkCFr-xDJa-vXfi4qgatKra?dl=0">Lab7</a></p>
  </li>
  <li>
    <p>Labs submission: see <a href="https://www.dropbox.com/s/uku3wz8i6xx3sjf/Labs-instrucctions.docx?dl=0" title="instructions">instructions</a>.</p>
  </li>
  <li>
    <p>Exams schedule on Fridays:<br />
E1-W2, E2-W4, E3-W6, E4-W9, E5-W12, E6-W14, E7-W1-12</p>
  </li>
  <li>
    <p>Labs on Mondays: L1-W3; L2-W5; L3-W7; L4-W10; L5-W13; L6-W15, L7-W17.</p>
  </li>
</ol>

<h3 id="information-sources">Information Sources</h3>

<ol>
  <li>
    <p>Han, J., Kamber, M. y Pei, J. (2011). Data Mining: Concepts and Techniques. Editorial Morgan Kaufman.  </p>
  </li>
  <li>
    <p>Ian H y Frank Eibe (2005), Data mining: Practical Machine Learning Tools and Techniques Witten. Editorial Morgan Kaufmann.  </p>
  </li>
  <li>
    <p>José Hernández Orallo, M.José Ramírez Quintana y Cèsar Ferri Ramírez (2004). Introducción a la Minería de Datos. Editorial Pearson.  </p>
  </li>
  <li>
    <p>Bing Liu (1998). Web Data Mining. Editorial Springer.  </p>
  </li>
  <li>
    <p>Dean J. (2014). Big Data, Data Mining, and Machine Learning: Value Creation for Business  Leaders and Practitioners. Wiley and SAS Business Series.  </p>
  </li>
  <li>
    <p>Richard S. Sutton y Andrew G. Barto (1998). Reinforcement Learning: An  introduction. MIT Press.  </p>
  </li>
  <li>Kudyba, S. (2014). Big Data, Maining, and Analytics: Components of Strategic  Decision Making. CRC Press.  </li>
  <li>
    <p>Hurwitz, J., Nugent, A., Halper, F., &amp; Kaufman, M. (2014). Big Data for Dummies. John Willey &amp; Sons.</p>
  </li>
  <li>
    <p>WEKA (download and datasets).<br />
http://www.cs.waikato.ac.nz/ml/weka/index.html</p>
  </li>
  <li>
    <p>UCI: Machine learning repository<br />
http://archive.ics.uci.edu/ml/</p>
  </li>
  <li>Book list for machine learning.<br />
http://homepages.inf.ed.ac.uk/rbf/IAPR/researchers/MLPAGES/mlbks.htm</li>
</ol>

  </main>
</body>
</html>
